{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vanshbansal/Desktop/FuelGrowth'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/vanshbansal/Desktop/FuelGrowth\")\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ResultTransformationConfig:\n",
    "    influencer_avg_main_dir: Path\n",
    "    influence_total_score_dir: Path\n",
    "    urls_score_main_dir: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import read_yaml , write_yaml , create_directories\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                ):\n",
    "        \n",
    "        self.config=read_yaml(config_filepath)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_result_transformation_config(self)-> ResultTransformationConfig:\n",
    "        \n",
    "        transformation_config = self.config.result_transformation\n",
    "        \n",
    "        create_directories([transformation_config.influencer_avg_main_dir])\n",
    "        create_directories([transformation_config.influencer_avg_main_dir])\n",
    "        create_directories([transformation_config.influencer_avg_main_dir])\n",
    "\n",
    "        result_transformation_config = ResultTransformationConfig(\n",
    "            influencer_avg_main_dir = transformation_config.influencer_avg_main_dir,\n",
    "            influence_total_score_dir = transformation_config.influence_total_score_dir,\n",
    "            urls_score_main_dir = transformation_config.urls_score_main_dir\n",
    "        )\n",
    "\n",
    "        return result_transformation_config\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "from imagehash import phash\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from src import logger\n",
    "import shutil\n",
    "\n",
    "# Directory to store temporary frames\n",
    "\n",
    "\n",
    "\n",
    "class ResultTransformation:\n",
    "    def __init__(self , config:ResultTransformationConfig):\n",
    "        try:\n",
    "            self.config = config\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def is_directory_empty(self , directory_path):\n",
    "        \"\"\"Check if a directory is empty.\"\"\"\n",
    "        if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "            return len(os.listdir(directory_path)) == 0\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"The directory '{directory_path}' does not exist or is not a directory.\")\n",
    "            \n",
    "\n",
    "    \n",
    "    def transform_url_data(self , new_urls_path):\n",
    "        main_url_dir = self.config.urls_score_main_dir\n",
    "        \n",
    "        # If no files exist in the dir , we will just copy the latest clean_url file.\n",
    "        # This means we are running the pipeline for the first time.\n",
    "        if self.is_directory_empty(main_url_dir):\n",
    "            \n",
    "            destination_file_path = os.path.join(main_url_dir, \"clean_data.xlsx\")\n",
    "            logger.info(f\"Directory is empty, saving new urls to path: {destination_file_path}\")\n",
    "            shutil.copy(new_urls_path, destination_file_path)\n",
    "            logger.info(f\"File saved at path: {destination_file_path}\")\n",
    "\n",
    "            return destination_file_path\n",
    "        \n",
    "        # Data/urls already exist at that path\n",
    "        else:\n",
    "            logger.info(\"Trying to merge existing and current urls data...\")\n",
    "            main_url_dir = self.config.urls_score_main_dir\n",
    "            main_file_path = os.path.join(main_url_dir , \"clean_data.xlsx\")\n",
    "            curr_file_path = new_urls_path\n",
    "            \n",
    "            df_main = pd.read_excel(main_file_path)\n",
    "            df_curr = pd.read_excel(curr_file_path)\n",
    "\n",
    "            # Concatenate the two DataFrames\n",
    "            df_combined = pd.concat([df_main, df_curr])\n",
    "\n",
    "            # Drop duplicates based on the 'URL' column\n",
    "            df_combined = df_combined.drop_duplicates(subset='url', keep='first').reset_index(drop=True)\n",
    "\n",
    "            # Save the resulting DataFrame if needed\n",
    "            df_combined.to_excel(main_file_path)\n",
    "\n",
    "            logger.info(\"existing and current urls data merged successfully !!!\")\n",
    "\n",
    "            return main_file_path\n",
    "    \n",
    "\n",
    "    def create_and_save_final_inf_data(self , main_total_score_path):\n",
    "\n",
    "        avg_score_file_dir = self.config.influencer_avg_main_dir\n",
    "        avg_score_file_path = os.path.join(avg_score_file_dir , \"clean_data.xlsx\")\n",
    "        \n",
    "        logger.info(f\"Reading df at path: {main_total_score_path}\")\n",
    "        df = pd.read_excel(main_total_score_path)\n",
    "        df['avg_score'] = df['total_score']/df['no_of_occurance']\n",
    "        df = df.sort_values(by='avg_score', ascending=False)\n",
    "\n",
    "        df.to_excel(avg_score_file_path)\n",
    "        \n",
    "        logger.info(f\"Final avg data saved to path: {avg_score_file_path}\")\n",
    "\n",
    "        return main_total_score_path\n",
    "        \n",
    "\n",
    "\n",
    "    def transform_total_score_data(self , new_inf_total_score_path):\n",
    "        main_total_score_dir = self.config.influence_total_score_dir\n",
    "        logger.info(f\"new total score data is at path: {new_inf_total_score_path}\")\n",
    "\n",
    "\n",
    "        # If no files exist in the dir , we will just copy the latest influencer total score file.\n",
    "        # This means we are running the pipeline for the first time.\n",
    "        if self.is_directory_empty(main_total_score_dir):\n",
    "            \n",
    "            destination_file_path = os.path.join(main_total_score_dir, \"clean_data.xlsx\")\n",
    "            \n",
    "            logger.info(f\"Directory is empty, saving new total_score data to path: {destination_file_path}\")\n",
    "            shutil.copy(new_inf_total_score_path, destination_file_path)\n",
    "            logger.info(f\"File saved at path: {destination_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "            # Saving final results\n",
    "            return self.create_and_save_final_inf_data(destination_file_path)\n",
    "        else:\n",
    "            logger.info(\"A file for influencer total score data already exists\")\n",
    "\n",
    "\n",
    "            main_total_score_dir = self.config.influencer_avg_main_dir\n",
    "            main_total_score_path = os.path.join(main_total_score_dir , \"clean_data.xlsx\")\n",
    "            curr_total_score_path = new_inf_total_score_path\n",
    "\n",
    "            logger.info(\"Combining both new and existing data\")\n",
    "            df_main = pd.read_excel(main_total_score_path)\n",
    "            df_curr = pd.read_excel(curr_total_score_path)\n",
    "\n",
    "            # Concatenate the two dataframes\n",
    "            df_combined = pd.concat([df_main, df_curr])\n",
    "\n",
    "            # Group by 'hash' and sum 'total_score'\n",
    "            df_combined = df_combined.groupby('hash', as_index=False).agg({\n",
    "                'serial_num' : 'first',\n",
    "                'image_path': 'first',\n",
    "                'total_score': 'sum',  # Sum scores\n",
    "                'no_of_occurance': 'sum',       # Keep the first occurrence\n",
    "                'recent_occurance': 'max'       # Keep the max value\n",
    "\n",
    "            })\n",
    "\n",
    "            # Saving the combined dataframe\n",
    "            df_combined.to_excel(main_total_score_path)\n",
    "            logger.info(f\"Combined data saved to path: {main_total_score_path}\")\n",
    "            \n",
    "\n",
    "            # Saving final results\n",
    "            return self.create_and_save_final_inf_data(main_total_score_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-01 23:04:37,936: INFO: common: yaml file: config.yaml loaded successfully]\n",
      "[2024-12-01 23:04:37,965: INFO: common: created directory at: main_data/influencer_avg_data]\n",
      "[2024-12-01 23:04:37,967: INFO: common: created directory at: main_data/influencer_avg_data]\n",
      "[2024-12-01 23:04:37,968: INFO: common: created directory at: main_data/influencer_avg_data]\n",
      "[2024-12-01 23:04:37,972: INFO: 696704311: Directory is empty, saving new urls to path: main_data/urls_score data/clean_data.xlsx]\n",
      "[2024-12-01 23:04:37,981: INFO: 696704311: File saved at path: main_data/urls_score data/clean_data.xlsx]\n",
      "main_data/urls_score data/clean_data.xlsx\n",
      "[2024-12-01 23:04:37,981: INFO: 696704311: Current total score data is at path: temp_data/model_training_data/2024-12-01_21-48-11.xlsx]\n",
      "[2024-12-01 23:04:37,982: INFO: 696704311: Directory is empty, saving new total_score data to path: main_data/model_training_data/clean_data.xlsx]\n",
      "[2024-12-01 23:04:37,985: INFO: 696704311: File saved at path: main_data/model_training_data/clean_data.xlsx]\n",
      "[2024-12-01 23:04:37,986: INFO: 696704311: Reading df at path: main_data/model_training_data/clean_data.xlsx]\n",
      "[2024-12-01 23:04:38,674: INFO: 696704311: Final avg data saved to path: main_data/influencer_avg_data/clean_data.xlsx]\n",
      "main_data/model_training_data/clean_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    result_transform_config = config.get_result_transformation_config()\n",
    "    result_transform = ResultTransformation(config=result_transform_config)\n",
    "\n",
    "    final_url_path = result_transform.transform_url_data(\"temp_data/url_score data/clean/2024-12-01_21-47-59.xlsx\")\n",
    "    print(final_url_path)\n",
    "    \n",
    "    final_avg_score_path = result_transform.transform_total_score_data(\"temp_data/model_training_data/2024-12-01_21-48-11.xlsx\")\n",
    "    print(final_avg_score_path)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
